{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "762e16b8",
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m'Python 3.12.3'(으)로 셀을 실행하려면 ipykernel 패키지가 필요합니다.\n",
      "\u001b[1;31m필요한 패키지를 사용하여 <a href='command:jupyter.createPythonEnvAndSelectController'>Python 환경 만들기</a>\n",
      "\u001b[1;31m또는 다음 명령을 사용하여 'ipykernel'을(를) 설치합니다. 'c:/Users/daewoo/AppData/Local/Programs/Python/Python312/python.exe -m pip install ipykernel -U --user --force-reinstall'"
     ]
    }
   ],
   "source": [
    "import os\n",
    "# import requests\n",
    "# import streamlit as st\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "import google.generativeai as genai\n",
    "# from google.generativeai import GenerationConfig\n",
    "from langchain_google_genai import ChatGoogleGenerativeAI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62c97b03",
   "metadata": {},
   "outputs": [],
   "source": [
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3560984",
   "metadata": {},
   "outputs": [],
   "source": [
    "api_key = os.getenv(\"GOOGLE_API_KEY\") # GEMINI_API_KEY 키에 해당하는 value를 가져온다 (=api key)\n",
    "print(api_key[:-5]) # 보안상의 이유로 끝의 5자리는 생략!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a6369d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# api key를 등록, 저장\n",
    "# 이 코드를 실행함으로써 Gemini 모델 객체를 만들거나 generate_content()와 같은 api 호출 메소드를 반복해서 실행할 때 매번 key를 넘기지 않아도 된다. -> 일종의 프로젝트 key 전역설정\n",
    "genai.configure(api_key=os.getenv(\"GOOGLE_API_KEY\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ef0257b",
   "metadata": {},
   "source": [
    "# Gemini API 가격 및 사용 가능 토큰 확인\n",
    "https://ai.google.dev/gemini-api/docs/pricing?hl=ko"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34e0298a",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = genai.GenerativeModel('gemini-2.5-flash')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d4b4993",
   "metadata": {},
   "outputs": [],
   "source": [
    "model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de0be30a",
   "metadata": {},
   "source": [
    "# Chapter 1. Gemini에 직접 질문을 해서 답변을 받아보자!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77255c1f",
   "metadata": {},
   "source": [
    "## reponse : LLM 모델의 답변\n",
    "- response.text → 최종 생성 텍스트\n",
    "- response.candidates → 여러 후보 응답\n",
    "- response.usage_metadata → 토큰 사용량 정보\n",
    "\n",
    "etc..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae2d8b6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. generate_content(text) 내의 문장(text)을 프롬프트로 LLM 모델에게 전달\n",
    "# 2. generate_content() : Google Gemini API 서버에 요청\n",
    "# 3. response : LLM 모델이 내놓은 답변 (여러 정보 확인 가능)\n",
    "response = model.generate_content(\"안녕하세요, Gemini API 테스트 중입니다.\") # 질문 입력"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05e6fa90",
   "metadata": {},
   "outputs": [],
   "source": [
    "response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1eb9a1ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(response.text)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ed9b3c8",
   "metadata": {},
   "source": [
    "# Chapter 2. 우리의 대화를 기억하게 하자\n",
    "- 지금까지의 대화 세션을 저장, 메모리 캐싱해서 추가적인 질문 없이 Gemini가 직접 대화를 검색하도록 하는 방법\n",
    "> 동일한 질문에 대한 답변을 저장, 메모리에 저장된 답변을 반환\n",
    "- 토큰 사용량이 줄어듦\n",
    "- 대답 속도 향상"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aad7305c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.globals import set_llm_cache\n",
    "from langchain.cache import InMemoryCache\n",
    "from langchain_core.prompts import PromptTemplate\n",
    "from langchain_core.output_parsers import StrOutputParser"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb3e1a80",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 인메모리 캐시를 사용합니다.\n",
    "set_llm_cache(InMemoryCache())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aebfc9a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "llm = ChatGoogleGenerativeAI(model=\"gemini-2.5-flash\")\n",
    "\n",
    "prompt = PromptTemplate.from_template(\"{country}에 대해서 설명해줘. 최대한 짧게!\")\n",
    "\n",
    "chain = prompt | llm | StrOutputParser()\n",
    "\n",
    "print(chain.invoke({\"country\": \"미국\"}))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa9afd25",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "# 체인을 실행합니다.\n",
    "response = chain.invoke({\"country\": \"미국\"})\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a21301ec",
   "metadata": {},
   "source": [
    "# Chapter 3. 우리가 원하는 포맷으로 답변을 받아보자!\n",
    "- Few Shot 프롬프트 : 원하는 답변 포맷을 여러 예시로 제공하는 방법\n",
    "- LLM 모델은 Few shot에서 지정한 포맷을 맞춰 답변을 제공"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48bcccd7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.prompts.few_shot import FewShotPromptTemplate\n",
    "from langchain_core.prompts import PromptTemplate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78450006",
   "metadata": {},
   "outputs": [],
   "source": [
    "examples = [\n",
    "    {\n",
    "        \"question\": \"최근 가장 급등한 주식 종목 알려줘\",\n",
    "\n",
    "        \"answer\": \"\"\"\n",
    "추가 질문: 미국 주식 중 3개를 알려줘\n",
    "중간 답변: 최근 엔비디아, 구글, 메타가 가장 많이 올랐습니다.\n",
    "최종 답변은: 엔비디아, 테슬라, 팔란티어가 가장 많이 올랐습니다.\n",
    "\"\"\"}\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e81549b",
   "metadata": {},
   "outputs": [],
   "source": [
    "example_prompt = PromptTemplate.from_template(\n",
    "\"Question:\\n{question}\\nAnswer:\\n{answer}\"\n",
    ")\n",
    "\n",
    "print(example_prompt.format(**examples[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5eedf7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt = FewShotPromptTemplate(\n",
    "    examples=examples,\n",
    "    example_prompt=example_prompt,\n",
    "    suffix=\"Question:\\n{question}\\nAnswer:\",\n",
    "    input_variables=[\"question\"],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2bfc7ac0",
   "metadata": {},
   "outputs": [],
   "source": [
    "question = \"최근 1년 동안 가장 많이 오른 한국 주식 알려줘\"\n",
    "final_prompt = prompt.format(question=question)\n",
    "print(final_prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a9bb7cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "response = model.generate_content(final_prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8be94dd2",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(response.text)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
